# LibX264

`avcodec_send_frame` 和 `avcodec_receive_packet` 是 FFmpeg 的 API 函数，用于处理编码和解码任务。当你使用这些函数并选择 H.264 编码器（如 `libx264`）时，内部会调用 libx264 库进行实际的编码工作。

```c++
AVCodec* codec = avcodec_find_encoder(AV_CODEC_ID_H264);
AVCodecContext* codec_ctx = avcodec_alloc_context3(codec);
codec_ctx->bit_rate = 400000;
codec_ctx->width = 1280;
codec_ctx->height = 720;
codec_ctx->time_base = (AVRational){1, 25};
codec_ctx->framerate = (AVRational){25, 1};
codec_ctx->gop_size = 10;
codec_ctx->max_b_frames = 1;
codec_ctx->pix_fmt = AV_PIX_FMT_YUV420P;

if (avcodec_open2(codec_ctx, codec, NULL) < 0) {
    fprintf(stderr, "Could not open codec\n");
    exit(1);
}

AVFrame* frame = av_frame_alloc();
frame->format = codec_ctx->pix_fmt;
frame->width = codec_ctx->width;
frame->height = codec_ctx->height;
av_frame_get_buffer(frame, 0);

// Fill frame with data...

if (avcodec_send_frame(codec_ctx, frame) < 0) {
    fprintf(stderr, "Error sending frame for encoding\n");
    exit(1);
}

AVPacket* pkt = av_packet_alloc();
if (avcodec_receive_packet(codec_ctx, pkt) == 0) {
    // Encoded packet is ready to be written to file
    fwrite(pkt->data, 1, pkt->size, output_file);
    av_packet_unref(pkt);
}

av_frame_free(&frame);
av_packet_free(&pkt);
avcodec_free_context(&codec_ctx);

```

## 命令行

![image-20240611162403789](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20240611162403789.png)

![image-20240611165604178](D:\typora-image\image-20240611165604178.png)



## 帧、片（Slice）和宏块（Macroblock）

在视频编码中，帧、片（Slice）和宏块（Macroblock）之间的关系是分层的，理解这些概念有助于理解视频编码的过程。

### 帧（Frame）
帧是视频的基本单位。视频是一系列连续帧的集合，每一帧是一幅静止的图像。在视频播放过程中，这些帧以一定的速率（通常是每秒24帧、30帧或60帧）连续显示，产生运动的视觉效果。

### 片（Slice）
片是帧的一部分。一个帧可以被划分为多个片，每个片独立编码。片的划分可以提高错误恢复能力，因为即使一个片出现错误，其他片仍然可以正确解码。片的划分方式有两种主要类型：
- **横向划分**：将帧水平切成若干条带，每条带是一个片。
- **垂直划分**：将帧垂直切成若干列，每列是一个片。

### 宏块（Macroblock）
宏块是片的基本组成单元。传统的视频编码标准（如H.264/AVC）中，每个宏块通常是16x16像素的块。在现代视频编码标准（如H.265/HEVC）中，引入了编码树单元（CTU）来替代宏块，CTU可以更大（如64x64像素），并且可以更灵活地划分。

宏块包含：
- **亮度块（Luma Block）**：表示亮度信息。
- **色度块（Chroma Block）**：表示颜色信息。由于人眼对亮度变化更敏感，色度块通常比亮度块分辨率低（例如4:2:0采样中，色度块大小是8x8像素）。

### 关系示意
1. **帧**：整个图像。
2. **片**：帧被划分成的若干部分。
3. **宏块**：片被进一步划分成的更小的基本编码单元。

![image-20240611214244720](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20240611214244720.png)

![image-20240611215755617](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20240611215755617.png)

1. **视频帧划分**：视频帧被划分成若干片。
2. **片划分**：每个片被进一步划分成若干宏块。
3. **编码过程**：宏块进行预测、变换、量化和编码。
4. **NALU 封装**：编码后的数据片段被封装成 NALU，准备进行传输或存储。

### 示例
假设有一幅720p（1280x720像素）的帧：
1. 帧被划分成4个片，每个片为一条水平带，每个片包含180行像素。
2. 每个片再被划分成若干个宏块（16x16像素），一个片中有（1280 / 16） * (180 / 16) = 80 * 11 = 880个宏块。

在编码过程中，每个宏块单独处理，通过预测、变换、量化和熵编码等步骤进行压缩。解码时，这些宏块再被重组，恢复成片，最终恢复成完整的帧，进行播放。



## api与数据结构

![image-20240611181524472](D:\typora-image\image-20240611181524472.png)





## 代码：

![image-20240611203813164](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20240611203813164.png)

```c++
#include <x264.h>
#include <stdio.h>

int main() {
    x264_param_t param;
    x264_t *encoder;
    x264_picture_t pic_in, pic_out;
    FILE *outfile;
    int frame_size;

    // 设置编码参数
    x264_param_default_preset(&param, "veryfast", "zerolatency");
    param.i_bitdepth = 8;
    param.i_csp = X264_CSP_I420;
    param.i_width = 640;
    param.i_height = 480;
    param.i_fps_num = 25;
    param.i_fps_den = 1;
    param.rc.i_bitrate = 400;
    //..........................

    x264_param_apply_profile(&param, "high");

    // 打开编码器
    encoder = x264_encoder_open(&param);
    if (!encoder) {
        fprintf(stderr, "Could not open encoder\n");
        return -1;
    }

    // 分配和初始化输入图像
    x264_picture_alloc(&pic_in, param.i_csp, param.i_width, param.i_height);
    
    // 打开输出文件
    outfile = fopen("output.h264", "wb");
    if (!outfile) {
        fprintf(stderr, "Could not open output file\n");
        return -1;
    }

    //*********循环读取文件填充数据进行编码
    // 填充输入图像的 YUV 数据 (这里假设已经有图像数据填充到 pic_in.plane 中)
    
             fread(pPic_in->img.plane[0], y_size, 1, fp_src);         //Y
			fread(pPic_in->img.plane[1], y_size / 4, 1, fp_src);       //U
			fread(pPic_in->img.plane[2], y_size / 4, 1, fp_src);       //V

    // 编码帧
             frame_size = x264_encoder_encode(encoder, &pic_out, &pic_in);
    //*********循环读取文件填充数据进行编码
    
    
    
    if (frame_size < 0) {
        fprintf(stderr, "Error encoding frame\n");
        return -1;
    }
    fwrite(pic_out.p_payload, 1, frame_size, outfile);

    // 释放资源
    x264_picture_clean(&pic_in);
    x264_encoder_close(encoder);
    fclose(outfile);

    return 0;
}

```





### AVframe拷贝到X264_pic示例代码

假设图像宽度为 `m_width`，高度为 `m_height`，并且YUV420P格式的图像数据存储在AVFrame中。可以计算出每个平面的总字节数，然后进行一次性拷贝。

```c
// Y平面数据总字节数
int y_plane_size = m_height * frame->linesize[0];
// U平面数据总字节数
int u_plane_size = (m_height / 2) * frame->linesize[1];
// V平面数据总字节数
int v_plane_size = (m_height / 2) * frame->linesize[2];

// 复制Y平面数据
memcpy(pic_in.img.plane[0], frame->data[0], y_plane_size);

// 复制U平面数据
memcpy(pic_in.img.plane[1], frame->data[1], u_plane_size);

// 复制V平面数据
memcpy(pic_in.img.plane[2], frame->data[2], v_plane_size);
```

### 总字节数计算

- **Y平面总字节数**：`m_height * frame->linesize[0]`
- **U平面总字节数**：`(m_height / 2) * frame->linesize[1]`
- **V平面总字节数**：`(m_height / 2) * frame->linesize[2]`

### 示例代码解释

- **Y平面**：直接将整个Y平面数据从 `frame->data[0]` 复制到 `pic_in.img.plane[0]`。
- **U平面**：直接将整个U平面数据从 `frame->data[1]` 复制到 `pic_in.img.plane[1]`。
- **V平面**：直接将整个V平面数据从 `frame->data[2]` 复制到 `pic_in.img.plane[2]`。

### 进一步优化

如果确定 `frame->linesize` 和 `pic_in.img.i_stride` 是一致的（即每行的数据跨度相同），则可以安全地进行一次性拷贝。如果不确定，可以逐行检查和拷贝：

```c
if (frame->linesize[0] == pic_in.img.i_stride[0]) {
    memcpy(pic_in.img.plane[0], frame->data[0], y_plane_size);
} else {
    for (int y = 0; y < m_height; y++) {
        memcpy(pic_in.img.plane[0] + y * pic_in.img.i_stride[0], frame->data[0] + y * frame->linesize[0], m_width);
    }
}

if (frame->linesize[1] == pic_in.img.i_stride[1]) {
    memcpy(pic_in.img.plane[1], frame->data[1], u_plane_size);
} else {
    for (int y = 0; y < m_height / 2; y++) {
        memcpy(pic_in.img.plane[1] + y * pic_in.img.i_stride[1], frame->data[1] + y * frame->linesize[1], m_width / 2);
    }
}

if (frame->linesize[2] == pic_in.img.i_stride[2]) {
    memcpy(pic_in.img.plane[2], frame->data[2], v_plane_size);
} else {
    for (int y = 0; y < m_height / 2; y++) {
        memcpy(pic_in.img.plane[2] + y * pic_in.img.i_stride[2], frame->data[2] + y * frame->linesize[2], m_width / 2);
    }
}
```

### 总结

直接进行内存拷贝，可以大大简化代码并提高性能，但前提是目标内存块和源内存块在内存中的布局是连续的，并且不需要考虑内存对齐问题。在实际应用中，尤其是在处理大型图像数据时，一次性拷贝往往比逐行拷贝更加高效。



# libx265

![image-20240611214551139](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20240611214551139.png)

VPS：视频参数集，用于传输视频分级信息，有利于兼容标准在可分级视频编码或多视点视频的扩展。

H265 的 NALU 的头部由两个字节、

![image-20240612122203676](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20240612122203676.png)

![image-20240612123401827](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20240612123401827.png)







