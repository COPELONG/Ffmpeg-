# H264编码原理及实战

## 1.原理：

![image-20231012100711183](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231012100711183.png)



![image-20231012105554021](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231012105554021.png)

![image-20231012105755900](D:\typora-image\image-20231012105755900.png)

--------------

![image-20231012110023011](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231012110023011.png)

高频信息值变小，记录存储变得容易。

QP：量化

![image-20231012111902922](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231012111902922.png)

![image-20231012112642556](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231012112642556.png)

---------------

H.264 是一种先进的视频编码标准，其编码过程涉及多个步骤，以实现高效的视频压缩。以下是 H.264 编码的主要步骤：

### 1. 分块和分片

**宏块划分**
- 视频帧被分割成宏块（macroblocks），每个宏块通常是 16x16 像素的块。
- 宏块进一步划分为更小的子块，以提高压缩效率。

**分片**
- 一些视频帧可以被分割成多个片（slices），每片可以独立解码，这在网络传输中提高了鲁棒性。

### 2. 预测

**帧内预测（Intra Prediction）**
- 宏块基于同一帧内的相邻像素进行预测。H.264 提供了多种帧内预测模式，以选择最匹配的预测模式。

**帧间预测（Inter Prediction）**
- 宏块基于参考帧（通常是之前的帧）进行预测。通过运动估计（Motion Estimation）找到当前宏块在参考帧中的最佳匹配位置，然后使用运动补偿（Motion Compensation）进行预测。

### 3. 变换与量化

**离散余弦变换（DCT）**
- 预测残差（即实际值与预测值之间的差异）应用 4x4 或 8x8 块的离散余弦变换，将空间域的数据转换到频域，以便进一步压缩。

**量化**
- 变换后的系数进行量化，量化减少了精度从而降低数据量，但也引入了一些不可逆的损失。

### 4. 熵编码

**熵编码**是对量化后的数据和预测信息（如运动矢量、模式选择等）进行无损压缩的步骤。

- 量化后的系数使用熵编码（Entropy Coding）进行压缩。H.264 支持两种主要的熵编码方法：
- CAVLC（Context-Adaptive Variable-Length Coding） 
- CABAC（Context-Adaptive Binary Arithmetic Coding）。CABAC 更复杂但压缩效率更高。

### 5. 重建和环路滤波

**重建**
- 为了进行预测，编码器需要将量化后的数据逆变换和逆量化，重建出原始数据的近似值，并将其存储作为参考帧。

**去块效应滤波器（Deblocking Filter）**

- 为了减少块效应（blocking artifacts），H.264 引入了去块效应滤波器，对重建后的帧进行处理，使得相邻块的边缘更加平滑。

### 6. 比特流封装

**比特流封装**
- 最后，经过上述步骤处理的数据被封装成比特流，按照 H.264 标准的规定格式进行存储和传输。
- 生成 SODB 后，接下来的步骤是将 SODB 封装成 **NAL（Network Abstraction Layer）** 单元：
  1. **SODB 生成**：在编码的过程中，最终的比特流是纯数据位串，这就是 SODB。
  2. **RBSP 生成**：为了将 SODB 对齐到字节边界（每 8 位一个字节），在 SODB 后面添加填充位，生成 **RBSP（Raw Byte Sequence Payload）**。
  3. **EBSP 生成**：进一步将 RBSP 封装为 **EBSP（Encapsulated Byte Sequence Payload）**，以避免与 NAL 单元的起始码冲突（通常通过添加额外的转义字节 `0x03`）。
  4. **NAL 单元生成**：最终将 EBSP 封装为 NAL 单元，加上NAL单元头，形成实际输出的比特流，用于传输或存储。

### 总结

H.264 编码过程如下图所示：

```
输入帧 -> 分块与分片 -> 预测 (帧内/帧间) -> 变换 (DCT) -> 量化 -> 熵编码 -> 比特流封装
              ↑                               |
              |                               |
           重建帧 <- 逆变换 <- 逆量化 <- 熵解码 <-  解码器 (解码时使用)
              |
              -> 去块效应滤波 -> 输出重建帧
```

这些步骤共同作用，使得 H.264 能够在保证视频质量的同时实现高效的视频压缩和传输。



在H.264/AVC视频编码标准中，NALU（Network Abstraction Layer Unit）和RBSP（Raw Byte Sequence Payload）是视频流中数据封装和传输的基本单元。它们之间的关系如下：

### RBSP（Raw Byte Sequence Payload）
- **定义**：RBSP是H.264编码生成的原始比特流数据，包括编码后的图像数据、序列参数集（SPS）、图像参数集（PPS）等。
- **作用**：RBSP包含实际的编码信息和一些用于纠错和增强鲁棒性的冗余数据。
- **结构**：RBSP是纯数据流，包含原始的编码数据和附加的冗余比特，以确保数据的完整性和纠错能力。

### NALU（Network Abstraction Layer Unit）
- **定义**：NALU是H.264视频流的基本传输单元，每个NALU单元包含一个头部和一个RBSP数据块。
- **作用**：NALU负责封装RBSP数据，并附加头部信息，以便在网络上传输和解码器解析。
- **结构**：
  - **NALU头部**：包含NALU类型、参考级别等信息。
  - **RBSP数据**：包含实际的编码数据（图像数据、SPS、PPS等）。

### NALU与RBSP的关系
1. **封装关系**：
   - 每个NALU单元包含一个RBSP数据块。RBSP是NALU的数据部分。
   - NALU的头部信息加上RBSP数据构成一个完整的NALU单元。

2. **传输和解析**：
   - 编码器生成RBSP数据，并将其封装到NALU单元中。
   - 在网络传输过程中，NALU单元被传输到接收端。
   - 解码器接收NALU单元后，解析头部信息，并提取其中的RBSP数据进行解码。

3. **示例**：
   - 一个NALU单元可能包含一个完整的I帧、P帧、B帧的数据，也可能包含SPS或PPS等参数集。
   - NALU头部指示该单元包含的数据类型（例如，I帧、P帧、B帧、SPS、PPS等）。
   - 解码器根据NALU头部信息确定如何处理和解码其中的RBSP数据。

### 例子

```plaintext
+-------------------+---------------+
| NALU Header       | NALU Payload  |
| (1 byte)          | (RBSP Data)   |
+-------------------+---------------+
| 0x65              | ...           |  // NALU type 5: IDR slice (I-frame)
+-------------------+---------------+
| 0x67              | ...           |  // NALU type 7: SPS
+-------------------+---------------+
| 0x68              | ...           |  // NALU type 8: PPS
+-------------------+---------------+
```

在上述示例中：
- `0x65`是NALU头部，指示这是一个IDR帧（I帧）。
- `0x67`是NALU头部，指示这是一个SPS。
- `0x68`是NALU头部，指示这是一个PPS。

RBSP数据包含在这些NALU头部之后，解码器使用这些头部信息来处理和解码RBSP数据。

![image-20240611221801455](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20240611221801455.png)

![image-20240829091148382](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20240829091148382.png)

**SODB**是最基础的编码数据，只包含有意义的比特位。

**RBSP**通过在SODB基础上添加填充位，使数据对齐为字节。

**EBSP**在RBSP基础上通过转义处理，确保数据在传输过程中不会误识别为NAL单元的起始码。起始码（例如NAL起始码“0x000001”或“0x00000001”）用于标识NAL单元的开始，如果RBSP中恰好有与起始码相同的字节序列，就可能导致误解，为此需要进行转义。

- 一个NALU可以代表一个完整的帧吗？

- - 不可以，看nal_unit_type，5代表完整帧，1-4不一定是完整帧。

- 多个NAL单元组成一个Access Unit，多个Access Unit再组成一个视频编码序列（即原始视频的一帧一帧的像素数据经过编码之后的结构组成的序列）。













## 2.实战：

![image-20231012145624204](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231012145624204.png)

![image-20231012151357845](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231012151357845.png)

![image-20231012151343503](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231012151343503.png)

![image-20231012151422278](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231012151422278.png)



----------------------

```
ret = av_opt_set(codec_ctx->priv_data, "preset", "medium", 0);
```

![image-20231012151835233](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231012151835233.png)

-----------------

------------------------

![image-20231012154539445](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231012154539445.png)

![image-20231012154604892](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231012154604892.png)

-----------------

```
ret = av_frame_make_writable(frame);
```

![image-20231012155750309](D:\typora-image\image-20231012155750309.png)

-----------------------------

![image-20231012175448920](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231012175448920.png)

当设置**`codec_ctx->max_b_frames = 1`**说明存在B帧。

则编码器可能会等待更多的帧数据来推测B帧，以便更好地利用前后帧的信息进行更有效的压缩。一旦有足够的信息推测出B帧，I帧才会被写入文件。

发送第一帧数据I帧

发送第二帧数据B帧

利用I帧推测出B帧，写入第一帧数据I帧

发送第三帧数据P帧

利用P帧推测出B帧，写入第三帧数据P帧 。      

因为编码器会在一定程度上自主控制帧的写入文件顺序    I-P-B

![image-20231017220353250](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231017220353250.png)

![image-20231017220213066](https://my-figures.oss-cn-beijing.aliyuncs.com/Figures/image-20231017220213066.png)

-----------------

# 代码：

总体流程和音频编码类似，参考音频编码代码

区别：

```c++
av_frame_get_buffer(frame, 0);

//编码器参数设置有所不同

    /* 设置分辨率*/
    codec_ctx->width = 1280;
    codec_ctx->height = 720;
    /* 设置time base */
    codec_ctx->time_base = (AVRational){1, 25};
    codec_ctx->framerate = (AVRational){25, 1};
    /* 设置I帧间隔
     * 如果frame->pict_type设置为AV_PICTURE_TYPE_I, 则忽略gop_size的设置，一直当做I帧进行编码
     */
    codec_ctx->gop_size = 25;   // I帧间隔
    codec_ctx->max_b_frames = 2; // 如果不想包含B帧则设置为0
    codec_ctx->pix_fmt = AV_PIX_FMT_YUV420P;
codec_ctx->XXX  =  XXX;
......
av_opt_set(codec_ctx->priv_data, "preset", "medium", 0);
av_opt_set(codec_ctx->priv_data, "profile", "main", 0); 
av_opt_set(codec_ctx->priv_data, "tune","zerolatency",0);
......
//：计算每一帧数据YUV的大小
//音频：av_get_bytes_per_sample(frame->format) * frame->channels * frame->nb_samples;
int frame_bytes = av_image_get_buffer_size(frame->format, frame->width,frame->height, 1);
uint8_t *yuv_buf = (uint8_t *)malloc(frame_bytes);

/*音频：av_samples_fill_arrays(frame->data, frame->linesize,pcm_buf, frame->channels,
                       frame->nb_samples, frame->format, 0);*/
 memset(yuv_buf, 0, frame_bytes);
 size_t read_bytes = fread(yuv_buf, 1, frame_bytes, infile);

av_image_fill_arrays(frame->data, frame->linesize, yuv_buf,frame->format,
frame->width, frame->height, 1);

//对 YUV 进行 H.264 编码时，默认情况下会自动编码成 Annex B 格式的数据流。
```

























































